{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-07-18T17:00:27.274657200Z",
     "start_time": "2023-07-18T17:00:27.248451600Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\360Downloads\\GPU-2.output\\tts-gan-my\n",
      "['.DS_Store', '不透水面', '不透水面-裸地', '植被', '植被-不透水面', '植被-稀疏植被', '植被-裸土', '水体', '水体-不透水面', '水体-裸土', '水体-裸土-不透水面', '水田', '水田-裸土', '稀疏植被', '稀疏植被-不透水面', '稀疏植被-裸土', '稀疏植被-裸土-稀疏植被', '耕地', '耕地-不透水面', '耕地-稀疏植被', '耕地-裸土', '裸土-不透水面', '裸土-水体', '裸土-稀疏植被', '裸地']\n",
      "Num of elements: 4437\n"
     ]
    }
   ],
   "source": [
    "base_dir = os.getcwd()\n",
    "print(base_dir)\n",
    "areas = os.listdir(base_dir + '/shenzhen')\n",
    "print(areas)\n",
    "add_ele = []\n",
    "for area in areas:\n",
    "    if area == '.DS_Store':\n",
    "        continue\n",
    "    dest = base_dir + '/shenzhen/' + area\n",
    "    t_dir = os.listdir(dest)\n",
    "    # print(t_dir)\n",
    "    for zone in t_dir:\n",
    "        if zone == '.DS_Store':\n",
    "            continue\n",
    "        items = os.listdir(dest + '/' + zone)\n",
    "        for ele in items:\n",
    "            if ele == '.DS_Store':\n",
    "                continue\n",
    "            add_ele.append(f'{dest}/{zone}/{ele}')\n",
    "\n",
    "print('Num of elements:', len(add_ele))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-18T15:04:36.956740Z",
     "start_time": "2023-07-18T15:04:36.896078500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4437/4437 [00:13<00:00, 320.62it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": "4437"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_lens = []\n",
    "raw_data = []\n",
    "for add in tqdm(add_ele):\n",
    "    # if add.count('.DS_Store'):\n",
    "    #     continue\n",
    "    df = pd.read_csv(add, usecols=['B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B8A', 'B11', 'B12', 'QA'],\n",
    "                     na_values=[0, -100])\n",
    "    has_null = df.iloc[:, :-1].isna().any().any()\n",
    "    # if has_null:\n",
    "    #     print(add)\n",
    "    #     break\n",
    "    df.interpolate(method='linear', inplace=True)\n",
    "    df.fillna(method='pad', inplace=True)\n",
    "    df.fillna(method='backfill', inplace=True)\n",
    "    df = df.astype('int')\n",
    "    raw_data.append(df.values.transpose())\n",
    "    csv_lens.append(df.shape)\n",
    "\n",
    "len(csv_lens)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-18T16:21:19.308935900Z",
     "start_time": "2023-07-18T16:21:05.446123200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "for idx, item in enumerate(csv_lens):\n",
    "    if item != (64, 11):\n",
    "        print(idx, item)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-18T15:07:23.308788300Z",
     "start_time": "2023-07-18T15:07:23.267786400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "data": {
      "text/plain": "(4437, 11, 1, 64)"
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_data = np.array(raw_data)\n",
    "np_data = np_data.reshape((-1, 11, 1, 64))\n",
    "np_data.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-18T17:23:33.666419Z",
     "start_time": "2023-07-18T17:23:33.639675400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class shenzhen_dataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 data_size=-1,  # 启用的数据数量\n",
    "                 path='./shenzhen/',  # shenzhen文件夹路径\n",
    "                 train_rate=0.8,  # 训练集占比\n",
    "                 data_mode='Train',  # 数据模式\n",
    "                 verbose=False\n",
    "                 ):\n",
    "        self.path = path\n",
    "        self.data_size = data_size\n",
    "        self.train_rate = train_rate\n",
    "        self.data_mode = data_mode\n",
    "        self.verbose = verbose\n",
    "\n",
    "        if not os.path.exists(self.path):\n",
    "            print('Path not existing!')\n",
    "            raise ValueError\n",
    "\n",
    "        assert self.data_mode == 'Train' or self.data_mode == 'Test'\n",
    "\n",
    "        # 加载所有文件目录\n",
    "        areas = os.listdir(self.path)\n",
    "        if self.verbose:\n",
    "            print(areas)\n",
    "        add_ele = []\n",
    "        for area in areas:\n",
    "            if area == '.DS_Store':\n",
    "                continue\n",
    "            dest = self.path + area\n",
    "            t_dir = os.listdir(dest)\n",
    "            # print(t_dir)\n",
    "            for zone in t_dir:\n",
    "                if zone == '.DS_Store':\n",
    "                    continue\n",
    "                items = os.listdir(dest + '/' + zone)\n",
    "                for ele in items:\n",
    "                    if ele == '.DS_Store':\n",
    "                        continue\n",
    "                    add_ele.append(f'{dest}/{zone}/{ele}')\n",
    "        if self.verbose:\n",
    "            print('Num of elements:', len(add_ele))\n",
    "\n",
    "        if self.data_size == -1:\n",
    "            self.data_size = len(add_ele)\n",
    "\n",
    "        # 读取所有CSV文件\n",
    "        self.raw_data = []\n",
    "        looper = zip(range(self.data_size), add_ele)\n",
    "        if self.verbose:\n",
    "            looper = tqdm(looper)\n",
    "        for idx, add in looper:\n",
    "            # if add.count('.DS_Store'):\n",
    "            #     continue\n",
    "            df = pd.read_csv(add, usecols=['B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B8A', 'B11', 'B12', 'QA'],\n",
    "                             na_values=[0, -100])\n",
    "            df.interpolate(method='linear', inplace=True)\n",
    "            df.fillna(method='pad', inplace=True)\n",
    "            df.fillna(method='backfill', inplace=True)\n",
    "            # has_null = df.isna().any().any()\n",
    "            # if has_null:\n",
    "            #     print(add)\n",
    "            #     raise ValueError\n",
    "            df = df.astype('float')\n",
    "            self.raw_data.append(df.values.transpose())\n",
    "\n",
    "        # 打乱原始数据\n",
    "        random.seed(777)\n",
    "        random.shuffle(self.raw_data)\n",
    "        # 转化为array，并reshape\n",
    "        self.np_data = np.array(self.raw_data)\n",
    "        self.np_data = self.np_data.reshape((-1, 11, 1, 64))\n",
    "        # 划分数据集\n",
    "        self.train_data = self.np_data[:self._train_size()]\n",
    "        self.test_data = self.np_data[self._train_size():]\n",
    "        # 正则化\n",
    "        self.normalization(self.train_data)\n",
    "        self.normalization(self.test_data)\n",
    "\n",
    "        if self.data_mode == 'Train':\n",
    "            self.shape = self.train_data.shape\n",
    "        if self.data_mode == 'Test':\n",
    "            self.shape = self.test_data.shape\n",
    "\n",
    "    def _normalize(self, epoch):\n",
    "        e = 1e-10\n",
    "        result = (epoch - epoch.mean(axis=0)) / ((np.sqrt(epoch.var(axis=0))) + e)\n",
    "        return result\n",
    "\n",
    "    def normalization(self, epochs):\n",
    "        for i in range(epochs.shape[0]):\n",
    "            for j in range(epochs.shape[1]):\n",
    "                epochs[i, j, 0, :] = self._normalize(epochs[i, j, 0, :])\n",
    "\n",
    "    def _train_size(self):\n",
    "        return int(self.data_size * self.train_rate)\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.data_mode == 'Train':\n",
    "            return len(self.train_data)\n",
    "        if self.data_mode == 'Test':\n",
    "            return len(self.test_data)\n",
    "        raise RuntimeError\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.data_mode == 'Train':\n",
    "            return self.train_data[idx], 7\n",
    "        if self.data_mode == 'Test':\n",
    "            return self.test_data[idx], 7\n",
    "        raise RuntimeError\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-18T20:00:10.732063800Z",
     "start_time": "2023-07-18T20:00:10.712072200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "outputs": [],
   "source": [
    "sz_train = shenzhen_dataset(data_size=1000, data_mode='Train', verbose=False)\n",
    "sz_test = shenzhen_dataset(data_size=1000, data_mode='Test', verbose=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-18T20:00:17.006867800Z",
     "start_time": "2023-07-18T20:00:11.382938800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[166], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43msz_train\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m123\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshape\u001B[49m\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'tuple' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "sz_train[123].shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-18T20:00:25.055714100Z",
     "start_time": "2023-07-18T20:00:24.999580400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [
    {
     "data": {
      "text/plain": "dtype('float64')"
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sz_test[0].dtype"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-18T19:17:39.663868100Z",
     "start_time": "2023-07-18T19:17:39.649842Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
